{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"vecs","text":"<p> <p> </p> </p> <p>Documentation: https://supabase.github.io/vecs/api/</p> <p>Source Code: https://github.com/supabase/vecs</p> <p>Vecs is a Python client library for managing and querying vector stores in PostgreSQL, leveraging the capabilities of the pgvector extension.</p>"},{"location":"#overview","title":"Overview","text":"<ul> <li>Vector Management: create collections to persist and update vectors in a PostgreSQL database.</li> <li>Querying: Query vectors efficiently using measures such as cosine distance, l2 distance, or max inner product.</li> <li>Metadata: Each vector can have associated metadata, which can also be used as filters during queries.</li> <li>Hybrid Data: vecs creates its own schema and can coexist with your existing relational data</li> </ul> <p>Visit the quickstart guide for how to get started.</p>"},{"location":"#tldr","title":"TL;DR","text":""},{"location":"#install","title":"Install","text":"<pre><code>pip install vecs\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<pre><code>import vecs\nDB_CONNECTION = \"postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\"\n# create vector store client\nvx = vecs.create_client(DB_CONNECTION)\n# create a collection of vectors with 3 dimensions\ndocs = vx.create_collection(name=\"docs\", dimension=3)\n# add records to the *docs* collection\ndocs.upsert(\nvectors=[\n(\n\"vec0\",           # the vector's identifier\n[0.1, 0.2, 0.3],  # the vector. list or np.array\n{\"year\": 1973}    # associated  metadata\n),\n(\n\"vec1\",\n[0.7, 0.8, 0.9],\n{\"year\": 2012}\n)\n]\n)\n# index the collection for fast search performance\ndocs.create_index()\n# query the collection filtering metadata for \"year\" = 2012\ndocs.query(\nquery_vector=[0.4,0.5,0.6],      # required\nlimit=1,                         # number of records to return\nfilters={\"year\": {\"$eq\": 2012}}, # metadata filters\n)\n# Returns: [\"vec1\"]\n# Disconnect from the database\nvx.disconnect()\n</code></pre>"},{"location":"api/","title":"API","text":"<p><code>vecs</code> is a python client for managing and querying vector stores in PostgreSQL with the pgvector extension. This guide will help you get started with using vecs.</p> <p>If you don't have a Postgres database with the pgvector ready, see hosting for easy options.</p>"},{"location":"api/#installation","title":"Installation","text":"<p>Requires:</p> <ul> <li>Python 3.7+</li> </ul> <p>You can install vecs using pip:</p> <pre><code>pip install vecs\n</code></pre>"},{"location":"api/#usage","title":"Usage","text":""},{"location":"api/#connecting","title":"Connecting","text":"<p>Before you can interact with vecs, create the client to communicate with Postgres. If you haven't started a Postgres instance yet, see hosting. <pre><code>import vecs\nDB_CONNECTION = \"postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\"\n# create vector store client\nvx = vecs.create_client(DB_CONNECTION)\n</code></pre></p>"},{"location":"api/#create-collection","title":"Create collection","text":"<p>You can create a collection to store vectors specifying the collections name and the number of dimensions in the vectors you intend to store.</p> <pre><code>docs = vx.create_collection(name=\"docs\", dimension=3)\n</code></pre> <p>Note</p> <p>If another collection exists with the same name, use get_collection to retrieve it.</p>"},{"location":"api/#get-an-existing-collection","title":"Get an existing collection","text":"<p>To access a previously created collection, use <code>get_collection</code> to retrieve it by name</p> <pre><code>docs = vx.get_collection(name=\"docs\")\n</code></pre>"},{"location":"api/#upserting-vectors","title":"Upserting vectors","text":"<p><code>vecs</code> combines the concepts of \"insert\" and \"update\" into \"upsert\". Upserting records adds them to the collection if the <code>id</code> is not present, or updates the existing record if the <code>id</code> does exist.</p> <pre><code># add records to the collection\ndocs.upsert(\nvectors=[\n(\n\"vec0\",           # the vector's identifier\n[0.1, 0.2, 0.3],  # the vector. list or np.array\n{\"year\": 1973}    # associated  metadata\n),\n(\n\"vec1\",\n[0.7, 0.8, 0.9],\n{\"year\": 2012}\n)\n]\n)\n</code></pre>"},{"location":"api/#create-an-index","title":"Create an index","text":"<p>Collections can be queried immediately after being created. However, for good performance, the collection should be indexed after records have been upserted.</p> <p>Indexes should be created after the collection has been populated with records. Building an index on an empty collection will result in significantly reduced recall. Once the index has been created you can still upsert new documents into the collection but you should rebuild the index if the size of the collection more than doubles.</p> <p>Only one index may exist per-collection. By default, creating an index will replace any existing index.</p> <p>To create an index:</p> <pre><code>##\n# INSERT RECORDS HERE\n##\n# index the collection to be queried by cosine distance\ndocs.create_index(measure=vecs.IndexMeasure.cosine_distance)\n</code></pre> <p>Available options for query <code>measure</code> are:</p> <ul> <li><code>vecs.IndexMeasure.cosine_distance</code></li> <li><code>vecs.IndexMeasure.l2_distance</code></li> <li><code>vecs.IndexMeasure.max_inner_product</code></li> </ul> <p>which correspond to different methods for comparing query vectors to the vectors in the database.</p> <p>If you aren't sure which to use, stick with the default (cosine_distance) by omitting the parameter i.e.</p> <pre><code>docs.create_index()\n</code></pre> <p>Note</p> <p>The time required to create an index grows with the number of records and size of vectors. For a few thousand records expect sub-minute a response in under a minute. It may take a few minutes for larger collections.</p>"},{"location":"api/#query","title":"Query","text":"<p>Given a collection <code>docs</code> with several records:</p>"},{"location":"api/#basic","title":"Basic","text":"<p>The simplest form of search is to provide a query vector.</p> <p>Note</p> <p>Indexes are essential for good performance. See creating an index for more info.</p> <p>If you do not create an index, every query will return a warning <pre><code>query does not have a covering index for cosine_similarity. See Collection.create_index\n</code></pre> that incldues the <code>IndexMeasure</code> you should index.</p> <pre><code>docs.query(\nquery_vector=[0.4,0.5,0.6],  # required\nlimit=5,                     # number of records to return\nfilters={},                  # metadata filters\nmeasure=\"cosine_distance\",   # distance measure to use\ninclude_value=False,         # should distance measure values be returned?\ninclude_metadata=False,      # should record metadata be returned?\n)\n</code></pre> <p>Which returns a list of vector record <code>ids</code>.</p>"},{"location":"api/#metadata-filtering","title":"Metadata Filtering","text":"<p>The metadata that is associated with each record can also be filtered during a query.</p> <p>As an example, <code>{\"year\": {\"$eq\": 2005}}</code> filters a <code>year</code> metadata key to be equal to 2005</p> <p>In context:</p> <pre><code>docs.query(\nquery_vector=[0.4,0.5,0.6],\nfilters={\"year\": {\"$eq\": 2012}}, # metadata filters\n)\n</code></pre> <p>For a complete reference, see the metadata guide.</p>"},{"location":"api/#disconnect","title":"Disconnect","text":"<p>When you're done with a collection, be sure to disconnect the client from the database.</p> <pre><code>vx.disconnect()\n</code></pre> <p>alternatively, use the client as a context manager and it will automatically close the connection on exit.</p> <pre><code>import vecs\nDB_CONNECTION = \"postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\"\n# create vector store client\nwith vecs.create_client(DB_CONNECTION) as vx:\n# do some work here\npass\n# connections are now closed\n</code></pre>"},{"location":"concepts_collections/","title":"Collections","text":"<p>A collection is an group of vector records. Records can be added to or updated in a collection. Collections can be queried at any time, but should be indexed for scalable query performance.</p> <p>Each vector record has the form:</p> <pre><code>Record (\nid: String\nvec: Numeric[]\nmetadata: JSON\n)\n</code></pre> <p>For example: <pre><code>(\"vec1\", [0.1, 0.2, 0.3], {\"year\": 1990})\n</code></pre></p> <p>Underneath every <code>vecs</code> a collection is Postgres table</p> <p><pre><code>create table &lt;collection_name&gt; (\nid string primary key,\nvec vector(&lt;dimension&gt;),\nmetadata jsonb\n)\n</code></pre> where rows in the table map 1:1 with vecs vector records.</p> <p>It is safe to select collection tables from outside the vecs client but issuing DDL is not recommended.</p>"},{"location":"concepts_indexes/","title":"Indexes","text":"<p>Indexes are tools for optimizing query performance of a collection.</p> <p>Collections can be queried without an index, but that will emit a python warning and should never be done in produciton.</p> <pre><code>query does not have a covering index for cosine_similarity. See Collection.create_index\n</code></pre> <p>as each query vector must be checked against every record in the collection. When the number of dimensions and/or number of records becomes large, that becomes extremely slow and computationally expensive.</p> <p>An index is a heuristic datastructure that pre-computes distances among key points in the vector space. It is smaller and can be traversed more quickly than the whole collection enabling much more performant seraching.</p> <p>Only one index may exist per-collection. An index optimizes a collection for searching according to a selected distance measure.</p> <p>Available options distance measure are:</p> <ul> <li>cosine distance</li> <li>l2 distance</li> <li>max inner product</li> </ul> <p>If you aren't sure which to use, stick with the default (cosine_distance) by omitting the parameter when creating indexes and querying.</p>"},{"location":"concepts_metadata/","title":"Metadata","text":"<p>vecs allows you to associate key-value pairs of metadata with indexes and ids in your collections. You can then add filters to queries that reference the metadata metadata.</p>"},{"location":"concepts_metadata/#types","title":"Types","text":"<p>Metadata is stored as binary JSON. As a result, allowed metadata types are drawn from JSON primitive types.</p> <ul> <li>Boolean</li> <li>String</li> <li>Number</li> </ul> <p>The technical limit of a metadata field associated with a vector is 1GB. In practice you should keep metadata fields as small as possible to maximize performance.</p>"},{"location":"concepts_metadata/#metadata-query-language","title":"Metadata Query Language","text":"<p>The metadata query language is based loosely on mongodb's selectors.</p> <p><code>vecs</code> currently supports a subset of those operators.</p>"},{"location":"concepts_metadata/#comparison-operators","title":"Comparison Operators","text":"<p>Comparison operators compare a provided value with a value stored in metadata field of the vector store.</p> Operator Description $eq Matches values that are equal to a specified value $ne Matches values that are not equal to a specified value $gt Matches values that are greater than a specified value $gte Matches values that are greater than or equal to a specified value $lt Matches values that are less than a specified value $lte Matches values that are less than or equal to a specified value"},{"location":"concepts_metadata/#logical-operators","title":"Logical Operators","text":"<p>Logical operators compose other operators, and can be nested.</p> Operator Description $and Joins query clauses with a logical AND returns all documents that match the conditions of both clauses. $or Joins query clauses with a logical OR returns all documents that match the conditions of either clause."},{"location":"concepts_metadata/#examples","title":"Examples","text":"<p><code>year</code> equals 2020</p> <pre><code>{\"year\": {\"$eq\": 2020}}\n</code></pre> <p><code>year</code> equals 2020 or <code>gross</code> greater than or equal to 5000.0</p> <pre><code>{\n\"$or\": [\n{\"year\": {\"$eq\": 2020}},\n{\"gross\": {\"$gte\": 5000.0}}\n]\n}\n</code></pre> <p><code>last_name</code> is less than \"Brown\" and <code>is_priority_customer</code> is true</p> <pre><code>{\n\"$and\": [\n{\"last_name\": {\"$lt\": \"Brown\"}},\n{\"is_priority_customer\": {\"$gte\": 5000.00}}\n]\n}\n</code></pre>"},{"location":"hosting/","title":"Deployment","text":"<p><code>vecs</code> is comatible with any Postgres 13+ with the pgvector extension installed.</p> <p>In the following we show we show instructions for hosting a database on Supabase and locally in docker since both are fast and free.</p>"},{"location":"hosting/#supabase","title":"Supabase","text":""},{"location":"hosting/#cloud-hosted","title":"Cloud Hosted","text":""},{"location":"hosting/#create-an-account","title":"Create an account","text":"<p>Create a supabase account at https://app.supabase.com/sign-up.</p> <p></p>"},{"location":"hosting/#create-a-new-project","title":"Create a new project","text":"<p>Select <code>New Project</code></p> <p></p> <p>Complete the prompts. Be sure to remember or write down your password as we'll need that when connecting with vecs.</p> <p></p>"},{"location":"hosting/#connection-info","title":"Connection Info","text":"<p>On the project page, navigate to <code>Settings</code> &gt; <code>Database</code> &gt; <code>Database Settings</code></p> <p></p> <p>and substitue those fields into the conenction string</p> <p><pre><code>postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\n</code></pre> i.e. <pre><code>postgres://postgres:[YOUR PASSWORD]@db.cvykdyhlwwwojivopztl.supabase.co:5432/postgres\n</code></pre></p> <p>Keep that connection string secret and safe. Its your <code>DB_CONNECTION</code> in the quickstart guide,</p>"},{"location":"hosting/#local","title":"Local","text":"<p>You can also use Supabase locally on your machine. Doing so will keep your project setup consistent when deploying to hosted Supabase.</p>"},{"location":"hosting/#install-the-cli","title":"Install the CLI","text":"<p>To install the CLI, use the relevant system instructions below</p> macOSWindowsLinuxnpm <pre><code>brew install supabase/tap/supabase\n</code></pre> <pre><code>scoop bucket add supabase https://github.com/supabase/scoop-bucket.git\nscoop install supabase\n</code></pre> <p>Linux packages are provided in Releases. To install, download the .apk/.deb/.rpm file depending on your package manager and run one of the following:</p> <p><pre><code>sudo apk add --allow-untrusted &lt;...&gt;.apk\n</code></pre> or <pre><code>sudo dpkg -i &lt;...&gt;.deb\n</code></pre> or <pre><code>sudo rpm -i &lt;...&gt;.rpm\n</code></pre></p> <pre><code>npm install supabase --save-dev\n</code></pre>"},{"location":"hosting/#start-the-project","title":"Start the Project","text":"<p>From your project directory, create the <code>supabase/</code> sub-directory required for supabase projects by running:</p> <pre><code>supabase init\n</code></pre> <p>next start the application using:</p> <pre><code>supabase start\n</code></pre> <p>which will download the latest Supabase containers and provide a URL to each service:</p> <pre><code>Seeding data supabase/seed.sql...me...\nStarted supabase local development setup.\n\n         API URL: http://localhost:54321\n     GraphQL URL: http://localhost:54321/graphql/v1\n          DB URL: postgresql://postgres:postgres@localhost:54322/postgres\n      Studio URL: http://localhost:54323\n    Inbucket URL: http://localhost:54324\n      JWT secret: super-secret-jwt-token-with-at-least-32-characters-long\n        anon key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFz\nservice_role key: eyJhbGciOiJIUzI1NiIsInR5cClJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU\n</code></pre> <p>The service we need for <code>vecs</code> is <code>DB URL</code>. Note it down for use as our <code>DB_CONNECTION</code></p> <pre><code>postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\n</code></pre> <p>For more info on running a local Supabase project, checkout the Supabase CLI guide</p>"},{"location":"hosting/#docker","title":"Docker","text":"<p>Install docker if you don't have it already at Get Docker</p>"},{"location":"hosting/#start-the-postgres-container","title":"Start the Postgres Container","text":"<p>Next, run <pre><code>docker run --rm -d \\\n--name vecs_hosting_guide \\\n-p 5019:5432 \\\n-e POSTGRES_DB=vecs_db \\\n-e POSTGRES_PASSWORD=password \\\n-e POSTGRES_USER=postgres \\\nsupabase/postgres:15.1.0.74\n</code></pre></p>"},{"location":"hosting/#connection-info_1","title":"Connection Info","text":"<p>Substitue the values from the previous section into the postgres conenction string</p> <p><pre><code>postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\n</code></pre> i.e. <pre><code>postgresql://postgres:password@localhost:5019/vecs_db\n</code></pre></p> <p>Keep that connection string secret and safe. Its your <code>DB_CONNECTION</code> in the quickstart guide</p>"},{"location":"integrations_huggingface_inference_endpoints/","title":"Integration: Hugging Face Inference Endpoints","text":"<p>This guide will walk you through an example integration of the Hugging Face Inference API with vecs. We will create embeddings using Hugging Face's <code>sentence-transformers/all-MiniLM-L6-v2</code> model, insert these embeddings into a PostgreSQL database using vecs, and then query vecs to find the most similar sentences to a given query sentence.</p>"},{"location":"integrations_huggingface_inference_endpoints/#create-a-hugging-face-inference-endpoint","title":"Create a Hugging Face Inference Endpoint","text":"<p>Head over to Hugging Face's inference endpoints and select <code>New Endpoint</code>.</p> <p></p> <p>Configure your endpoint with your model and provider of choice. In this example we'll use <code>sentence-transformers/all-MiniLM-L6-v2</code> and <code>AWS</code>.</p> <p></p> <p>Under \"Advanced Configuration\" select \"Sentence Embeddings\" as the \"Task\". Then click \"Create Endpoint\"</p> <p></p> <p>Once the endpoint starts up, take note of the <code>Endpoint URL</code> </p> <p>Tip</p> <p>Don't forget to pause or delete your Hugging Face Inference Endpoint when you're not using it</p> <p>Finally, create and copy an API key we can use to authenticate with the inference endpoint.</p>"},{"location":"integrations_huggingface_inference_endpoints/#create-an-environment","title":"Create an Environment","text":"<p>Next, you need to set up your environment. You will need Python 3.7+ with the vecs and requests installed.</p> <pre><code>pip install vecs requests\n</code></pre> <p>You'll also need a Postgres Database with the pgvector extension</p>"},{"location":"integrations_huggingface_inference_endpoints/#create-embeddings","title":"Create Embeddings","text":"<p>We can use the Hugging Face endpoint to create embeddings for a set of sentences.</p> <pre><code>import requests\nimport json\nhuggingface_endpoint_url = '&lt;HUGGINGFACE-ENDPOINT-URL&gt;'\nhuggingface_api_key = '&lt;HUGGINGFACE-API-KEY&gt;'\ndataset = [\n\"The cat sat on the mat.\",\n\"The quick brown fox jumps over the lazy dog.\",\n\"Friends, Romans, countrymen, lend me your ears\",\n\"To be or not to be, that is the question.\",\n]\nrecords = []\nfor sentence in dataset:\nresponse = requests.post(\nhuggingface_endpoint_url,\nheaders={\n\"Authorization\": f\"Bearer {huggingface_api_key}\",\n\"Content-Type\": \"application/json\"\n},\njson={\"inputs\": sentence}\n)\nembedding = response.json()[\"embeddings\"]\nrecords.append((sentence, embedding, {}))\n</code></pre>"},{"location":"integrations_huggingface_inference_endpoints/#store-the-embeddings-with-vecs","title":"Store the Embeddings with vecs","text":"<p>Now that we have our embeddings, we can insert them into a PostgreSQL database using vecs subbing in your DB_CONNECTION string.</p> <pre><code>import vecs\nDB_CONNECTION = \"postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\"\n# create vector store client\nvx = vecs.Client(DB_CONNECTION)\n# create a collection named 'sentences' with 384 dimensional vectors (default dimension for paraphrase-MiniLM-L6-v2)\nsentences = vx.create_collection(name=\"sentences\", dimension=384)\n# upsert the embeddings into the 'sentences' collection\nsentences.upsert(vectors=records)\n# create an index for the 'sentences' collection\nsentences.create_index()\n</code></pre>"},{"location":"integrations_huggingface_inference_endpoints/#querying-for-most-similar-sentences","title":"Querying for Most Similar Sentences","text":"<p>Finally, we can query vecs to find the most similar sentences to a given query sentence. The query sentence is embedded using the same method as the sentences in the dataset, then we query the <code>sentences</code> collection with vecs.</p> <pre><code>query_sentence = \"A quick animal jumps over a lazy one.\"\n# create an embedding for the query sentence\nresponse = requests.post(\nhuggingface_endpoint_url,\nheaders={\n\"Authorization\": f\"Bearer {huggingface_api_key}\",\n\"Content-Type\": \"application/json\"\n},\njson={\"inputs\": query_sentence}\n)\nquery_embedding = response.json()[\"embeddings\"]\n# query the 'sentences' collection for the most similar sentences\nresults = sentences.query(\nquery_vector=query_embedding,\nlimit=3,\ninclude_value = True\n)\n# print the results\nfor result in results:\nprint(result)\n</code></pre> <p>Returns the most similar 3 records and theirdistance to the query vector.</p> <pre><code>('The quick brown fox jumps over the lazy dog.', 0.256648302882697)\n('The cat sat on the mat.', 0.78635900041167)\n('To be or not to be, that is the question.', 1.04114070479544)\n</code></pre>"},{"location":"integrations_openai/","title":"Integration: Open AI","text":"<p>This guide will walk you through an example integration of the OpenAI API with the vecs Python library. We will create embeddings using OpenAI's <code>text-embedding-ada-002</code> model, insert these embeddings into a PostgreSQL database using vecs, and then query vecs to find the most similar sentences to a given query sentence.</p>"},{"location":"integrations_openai/#create-an-environment","title":"Create an Environment","text":"<p>First, you need to set up your environment. You will need Python 3.7 with the <code>vecs</code> and <code>openai</code> libraries installed.</p> <p>You can install the necessary Python libraries using pip:</p> <pre><code>pip install vecs openai\n</code></pre> <p>You'll also need:</p> <ul> <li>An OpenAI API Key</li> <li>A Postgres Database with the pgvector extension</li> </ul>"},{"location":"integrations_openai/#create-embeddings","title":"Create Embeddings","text":"<p>Next, we will use OpenAI's <code>text-embedding-ada-002</code> model to create embeddings for a set of sentences.</p> <pre><code>import openai\nopenai.api_key = '&lt;OPENAI-API-KEY&gt;'\ndataset = [\n\"The cat sat on the mat.\",\n\"The quick brown fox jumps over the lazy dog.\",\n\"Friends, Romans, countrymen, lend me your ears\",\n\"To be or not to be, that is the question.\",\n]\nembeddings = []\nfor sentence in dataset:\nresponse = openai.Embedding.create(\nmodel=\"text-embedding-ada-002\",\ninput=[sentence]\n)\nembeddings.append((sentence, response[\"data\"][0][\"embedding\"]))\n</code></pre>"},{"location":"integrations_openai/#store-the-embeddings-with-vecs","title":"Store the Embeddings with vecs","text":"<p>Now that we have our embeddings, we can insert them into a PostgreSQL database using vecs.</p> <pre><code>import vecs\nDB_CONNECTION = \"postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;db_name&gt;\"\n# create vector store client\nvx = vecs.Client(DB_CONNECTION)\n# create a collection named 'sentences' with 512 dimensional vectors (default dimension for text-embedding-ada-002)\nsentences = vx.create_collection(name=\"sentences\", dimension=1536)\n# upsert the embeddings into the 'sentences' collection\nsentences.upsert(vectors=embeddings)\n# create an index for the 'sentences' collection\nsentences.create_index()\n</code></pre>"},{"location":"integrations_openai/#querying-for-most-similar-sentences","title":"Querying for Most Similar Sentences","text":"<p>Finally, we can query vecs to find the most similar sentences to a given query sentence. We will first need to create an embedding for the query sentence using the <code>text-embedding-ada-002</code> model.</p> <pre><code>query_sentence = \"A quick animal jumps over a lazy one.\"\n# create an embedding for the query sentence\nresponse = openai.Embedding.create(\nmodel=\"text-embedding-ada-002\",\ninput=[query_sentence]\n)\nquery_embedding = response[\"data\"][0][\"embedding\"]\n# query the 'sentences' collection for the most similar sentences\nresults = sentences.query(\nquery_vector=query_embedding,\nlimit=3,\ninclude_value = True\n)\n# print the results\nfor result in results:\nprint(result)\n</code></pre> <p>Returns the most similar 3 records and their distance to the query vector. <pre><code>('The quick brown fox jumps over the lazy dog.', 0.0633971456300456)\n('The cat sat on the mat.', 0.16474785399561)\n('To be or not to be, that is the question.', 0.24531234467506)\n</code></pre></p>"},{"location":"support_changelog/","title":"Changelog","text":""},{"location":"support_changelog/#010","title":"0.1.0","text":"<p>Initial release</p>"}]}